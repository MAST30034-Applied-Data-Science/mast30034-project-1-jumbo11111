{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install package to read parquet files\n",
    "!pip3 install pyarrow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "all_years = [2021]\n",
    "all_months = ['09', '10', '11', '12']\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/'\n",
    "file_name = 'yellow_tripdata_%d-%s.parquet'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/curated/yellow_tripdata_2021-09.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m yellow_csv \u001B[38;5;241m=\u001B[39m file_name \u001B[38;5;241m%\u001B[39m (year, month)\n\u001B[1;32m      4\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget( url \u001B[38;5;241m+\u001B[39m yellow_csv, allow_redirects\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/curated/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43myellow_csv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mwrite(response\u001B[38;5;241m.\u001B[39mcontent)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/curated/yellow_tripdata_2021-09.parquet'"
     ]
    }
   ],
   "source": [
    "for year in all_years:\n",
    "    for month in all_months:\n",
    "        yellow_csv = file_name % (year, month)\n",
    "        response = requests.get( url + yellow_csv, allow_redirects=True)\n",
    "        open( '../data/raw/'+yellow_csv, 'wb').write(response.content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_yellow_trip_data = pd.DataFrame()\n",
    "\n",
    "for year in all_years:\n",
    "    for month in all_months:\n",
    "        yellow_csv = pd.read_parquet( file_name % (year, month) )\n",
    "        all_yellow_trip_data = all_yellow_trip_data.append('../data/raw/'+yellow_csv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_yellow_trip_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Missing data\n",
    "import numpy as np\n",
    "\n",
    "features_nan = [feature for feature in all_yellow_trip_data.columns if all_yellow_trip_data[feature].isnull().sum() > 1]\n",
    "for feature in features_nan:\n",
    "    print(f\"{feature}: {np.round(all_yellow_trip_data[feature].isnull().mean(), 4)}% missing values\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clean the empty data\n",
    "all_data_nonan = all_yellow_trip_data.dropna()\n",
    "all_data_nonan.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Look at the unique values for different columns\n",
    "for column in all_data_nonan.columns:\n",
    "    series = all_data_nonan[column]\n",
    "    print('Feature : ', column , ' min : ', series.min(), ' max : ', series.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleaned_data = all_data_nonan[all_data_nonan[\"passenger_count\"] > 0]\n",
    "cleaned_data  = cleaned_data [cleaned_data[\"trip_distance\"] != 0]\n",
    "cleaned_data  = cleaned_data [(cleaned_data ['tpep_pickup_datetime']<='2021-12-31 23:59:59') & (cleaned_data ['tpep_pickup_datetime']>='2021-09-01 00:00:00')]\n",
    "cleaned_data  = cleaned_data [(cleaned_data ['tpep_dropoff_datetime']<='2021-12-31 23:59:59') & (cleaned_data ['tpep_dropoff_datetime']>='2021-09-01 00:00:00')]\n",
    "\n",
    "cleaned_data = cleaned_data[cleaned_data[\"payment_type\"] == 1]\n",
    "cleaned_data = cleaned_data[cleaned_data[\"fare_amount\"] >= 2.5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_feature = ['fare_amount','tip_amount','total_amount']\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(9,9))\n",
    "#fig.suptitle(\"Outliers of amounts before cleaning\", fontsize=30, y=0.95)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "i = 0\n",
    "for k in check_feature:\n",
    "    cleaned_data.plot(y=k, kind='box', ax=axs.ravel()[i])\n",
    "    i += 1\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clean the outlier in amount feature\n",
    "amount = [\"fare_amount\", \"tip_amount\", \"total_amount\"]\n",
    "Q1 = cleaned_data[amount].quantile(0.25)\n",
    "Q3 = cleaned_data[amount].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "cleaned = cleaned_data[~((cleaned_data[amount] < (Q1-3*IQR)) | (cleaned_data[amount] > (Q3+3*IQR))).any(axis=1)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot result\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(9, 9))\n",
    "#fig.suptitle(\"Outliers of amounts after cleaning\", fontsize=30, y=0.95)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "i = 0\n",
    "for k in amount:\n",
    "    cleaned.plot(y=k, kind='box', ax=axs.ravel()[i])\n",
    "    i += 1\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Process time information into new features\n",
    "\n",
    "cleaned['month'] = pd.to_datetime(cleaned['tpep_pickup_datetime']).dt.month\n",
    "cleaned['day'] = pd.to_datetime(cleaned['tpep_pickup_datetime']).dt.day\n",
    "cleaned['week'] = pd.to_datetime(cleaned['tpep_pickup_datetime']).dt.week\n",
    "cleaned['weekday'] = pd.to_datetime(cleaned['tpep_pickup_datetime']).dt.weekday\n",
    "cleaned['starting_hour'] = pd.to_datetime(cleaned['tpep_pickup_datetime']).dt.hour\n",
    "cleaned['ending_hour'] = pd.to_datetime(cleaned['tpep_dropoff_datetime']).dt.hour\n",
    "cleaned['trip_time'] = (pd.to_datetime(cleaned['tpep_dropoff_datetime'])-pd.to_datetime(cleaned['tpep_pickup_datetime'])).dt.total_seconds()\n",
    "cleaned['date'] = cleaned['tpep_pickup_datetime'].apply(str).str[:13]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleaned.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('../data/curated/data_processed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "weather_data = pd.read_csv(\"../data/raw/weather_hourly.csv\")\n",
    "weather_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pick features\n",
    "weather_data_pick = weather_data[['datetime','feelslike','humidity','windspeed','visibility','solarradiation','conditions']]\n",
    "weather_data_pick['datetime'] = weather_data_pick['datetime'].str[:13]\n",
    "weather_data_pick['datetime'] = weather_data_pick['datetime'].str.replace('T',' ')\n",
    "\n",
    "weather_data_pick = weather_data_pick.join(pd.get_dummies(weather_data_pick.conditions,prefix='conditions'))\n",
    "#weather_data_pick = weather_data_pick.drop('conditions',axis=1)\n",
    "weather_data_pick.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weather_data_pick.to_csv('../data/curated/processed_weather.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in weather_data_pick.columns:\n",
    "    series =  weather_data_pick[column]\n",
    "    print('Feature : ', column , ' min : ', series.min(), ' max : ', series.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge to get new data\n",
    "data = pd.merge(cleaned, weather_data_pick, left_on='date', right_on='datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.drop(['datetime','date'],axis=1)\n",
    "data.head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.to_csv('../data/curated/processed.csv') # Save processe data to save time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}